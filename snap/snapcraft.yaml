name: spark-client
base: core20
version: '3.3.0'
summary: Client side scripts to submit Spark jobs to a cluster.
description: |
  The spark-client snap includes the scripts spark-submit, spark-shell, pyspark and other tools for managing Apache Spark jobs.

grade: stable
confinement: strict

plugs:
  enable-scala-history:
    interface: personal-files
    write:
    - $HOME/.scala_history
  enable-kubeconfig-access:
    interface: personal-files
    read:
    - $HOME/.kube/config

environment:
  JAVA_HOME: $SNAP/usr/lib/jvm/java-11-openjdk-amd64
  PATH: $JAVA_HOME/bin:$PATH

apps:
  setup-spark-k8s:
    command: ops/setup_wrapper.sh
    environment:
      PYTHONPATH: $PYTHONPATH:$SNAP/usr/lib/python3/dist-packages
      OPS_ROOT: ${SNAP}/ops
    plugs:
        - network
        - home
        - enable-kubeconfig-access
  spark-submit:
    command: bin/spark-submit
    plugs:
        - network
        - home
  spark-shell:
    command: bin/spark-shell
    plugs:
        - network
        - network-bind
        - home
        - enable-scala-history
  pyspark:
    command: bin/pyspark
    environment:
      PYTHONPATH: $PYTHONPATH:$SNAP/usr/lib/python3/dist-packages
    plugs:
        - network
        - network-bind
        - home

parts:
  spark:
    plugin: nil
    build-packages:
        - ca-certificates
        - ca-certificates-java
        - openjdk-11-jre-headless
        - python3
        - wget
    stage-packages:
        - openjdk-11-jre-headless
    override-build: |
        SPARK_VERSION='3.3.0'
        SPARK_HADOOP_VERSION='3'
        AWS_JAVA_SDK_BUNDLE_VERSION='1.11.874'
        HADOOP_AWS_VERSION='3.2.2'
        wget https://downloads.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${SPARK_HADOOP_VERSION}.tgz
        tar -zxf spark-${SPARK_VERSION}-bin-hadoop${SPARK_HADOOP_VERSION}.tgz
        cd spark-${SPARK_VERSION}-bin-hadoop${SPARK_HADOOP_VERSION}/jars
        wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/${AWS_JAVA_SDK_BUNDLE_VERSION}/aws-java-sdk-bundle-${AWS_JAVA_SDK_BUNDLE_VERSION}.jar
        wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/${HADOOP_AWS_VERSION}/hadoop-aws-${HADOOP_AWS_VERSION}.jar
        cd ..
        mkdir -p $SNAPCRAFT_PRIME/bin
        cp -r bin/* $SNAPCRAFT_PRIME/bin/
        mkdir -p $SNAPCRAFT_PRIME/jars
        cp -r jars/* $SNAPCRAFT_PRIME/jars/
        mkdir -p $SNAPCRAFT_PRIME/python
        cp -r python/* $SNAPCRAFT_PRIME/python/
    override-prime: |
        snapcraftctl prime
        rm -vf usr/lib/jvm/java-11-openjdk-*/lib/security/blacklisted.certs

  helper-scripts:
    plugin: python
    python-packages:
        - pyyaml
    build-packages:
        - curl
    source: helpers
    source-type: local
    override-build: |
      target_dir="${SNAPCRAFT_PRIME}/ops"
      
      rm -rf "${target_dir}"
      mkdir -p "${target_dir}"
      cp setup-spark-k8s.py "${target_dir}"/
      cp setup_wrapper.sh "${target_dir}"/
      chmod +x "${target_dir}"/setup_wrapper.sh
      
      curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
      chmod +x kubectl
      cp kubectl ${SNAPCRAFT_PRIME}/
      
      
